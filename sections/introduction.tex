\section{Introduction}
\label{chap:introduction}

In 2016 the world heard about a computer program named AlphaGo that in October 2015
won five to zero with Fan Hui, a Go professional and three-time European Champion. Later,
in March 2016 that same AI system won four to one with Lee Sedol, widely considered the
greatest player of that decade. Those revelations were groundbreaking considering that Go
was regarded as a major challenge for artificial intelligence. And yet AlphaGo managed not
only to master this game but also to devise innovative moves unknown to humans before \cite{AlphaGoBlog}.

Since then, we have noticed rapid development in this area. A crucial milestone was
the creation of AlphaGo Zero which, in contrast to its predecessors, used only reinforcement
learning during training and yet managed to outperform all of the older versions in only forty
days \cite{AlphaGoZeroBlog}. That opened up opportunities for AI to master other games like chess 
or shogi.

As a result, the question arises whether it is possible to create an artificial intelligence
agent that can repeat AlphaGo and AlphaGo Zero's success in the area of more complex
board games like \textit{Settlers of Catan}, \textit{Pandemic}, \textit{Azul}, etc. This 
project attempts to answer this question by preparing an agent for the \textit{Carcassonne} game 
using reinforcement learning and analysing its behaviour and ability to make optimal 
decisions in a dynamic environment.

The following sections present the achieved goals. The section `Game engine architecture' 
presents the architecture of the game engine, its components and communication within the entire system. `Agent architecture' 
concentrates on describing the structure of the game agent and neural network input and
output structure. Next, the section `Evaluation' describes a design of the conducted experiment 
and the analysis of the agent's performance and its strategies.
